"""ColdwellBankerCostaRica.com specific extractor.
"""

from typing import Optional
from bs4 import BeautifulSoup
from decimal import Decimal
import re
import openai
import json
from django.conf import settings
from .base import BaseExtractor


class ColdwellBankerExtractor(BaseExtractor):
    """Extractor for coldwellbankercostarica.com listings."""
    
    def __init__(self):
        super().__init__()
        self.site_name = "coldwellbankercostarica.com"
    
    def extract(self, html: str, url: Optional[str] = None) -> dict:
        """
        Override extract to use AI enhancement with clean text extraction.
        This reduces token usage by 98%+ and improves data quality.
        """
        soup = BeautifulSoup(html, 'html.parser')
        
        # Extract clean text from key sections
        text_content = self.extract_all_text(soup)
        
        # Log character count reduction
        original_chars = len(html)
        text_chars = len(text_content)
        reduction_pct = ((original_chars - text_chars) / original_chars * 100) if original_chars > 0 else 0
        print(f"ðŸ“ Texto limpio extraÃ­do: {text_chars} caracteres (vs {original_chars} chars HTML) - {reduction_pct:.1f}% reducciÃ³n")
        
        # Save to file for inspection
        try:
            with open('ai_input_text.txt', 'w', encoding='utf-8') as f:
                f.write(text_content)
            print(f"ðŸ’¾ Texto guardado en: ai_input_text.txt")
        except Exception as e:
            print(f"âš ï¸ Error guardando texto: {e}")
        
        # Enhance with AI
        enhanced_data = self.enhance_with_ai(text_content)
        
        if enhanced_data:
            return enhanced_data
        
        # Fallback to base extraction if AI fails
        print("âš ï¸ AI enhancement failed, falling back to base extraction")
        return super().extract(html)
    
    def extract_all_text(self, soup: BeautifulSoup) -> str:
        """
        Extract clean, structured text from key sections of Coldwell Banker pages.
        """
        sections = []
        
        # 1. TÃTULO Y PRECIO
        title_wrap = soup.find('div', class_='title-wrap')
        if title_wrap:
            sections.append("=== TÃTULO Y PRECIO ===")
            sections.append(title_wrap.get_text(separator='\n', strip=True))
            sections.append("")
        
        # 2. ESPECIFICACIONES (bedrooms, bathrooms, area, lot size)
        ul_specs = soup.find('ul', class_='ul-specs')
        if ul_specs:
            sections.append("=== ESPECIFICACIONES ===")
            for li in ul_specs.find_all('li'):
                spec_text = li.get_text(strip=True)
                if spec_text:
                    sections.append(spec_text)
            sections.append("")
        
        # 3. MÃS DETALLES (additional specifications)
        more_details = soup.find('div', class_='more-details')
        if more_details:
            sections.append("=== MÃS DETALLES ===")
            sections.append(more_details.get_text(separator='\n', strip=True))
            sections.append("")
        
        # 4. DESCRIPCIÃ“N COMPLETA
        desc_wrap = soup.find('div', class_='desc-wrap')
        if desc_wrap:
            sections.append("=== DESCRIPCIÃ“N ===")
            # Try complete description first
            desc_complete = desc_wrap.find('div', class_='desc-content-complete')
            if desc_complete:
                # Remove read-toggle links
                for link in desc_complete.find_all('a', class_='read-toggle'):
                    link.decompose()
                sections.append(desc_complete.get_text(separator='\n', strip=True))
            else:
                # Fallback to any desc-content
                desc_content = desc_wrap.find('div', class_='desc-content')
                if desc_content:
                    for link in desc_content.find_all('a', class_='read-toggle'):
                        link.decompose()
                    sections.append(desc_content.get_text(separator='\n', strip=True))
            sections.append("")
        
        # 5. CARACTERÃSTICAS/AMENIDADES
        features_section = soup.find('div', class_='property-features')
        if features_section:
            sections.append("=== CARACTERÃSTICAS ===")
            for li in features_section.find_all('li'):
                feature = li.get_text(strip=True)
                if feature:
                    sections.append(f"â€¢ {feature}")
            sections.append("")
        
        # 6. UBICACIÃ“N
        # Try h3 tags with location info
        for section in soup.find_all('section'):
            for h3 in section.find_all('h3'):
                text = h3.get_text(strip=True)
                if 'ubicaciÃ³n:' in text.lower() or 'location:' in text.lower():
                    sections.append("=== UBICACIÃ“N ===")
                    sections.append(text)
                    sections.append("")
                    break
        
        return '\n'.join(sections)
    
    def enhance_with_ai(self, text_content: str) -> Optional[dict]:
        """
        Use OpenAI to extract and enhance property data from clean text.
        """
        try:
            api_key = settings.OPENAI_API_KEY
            if not api_key:
                print("âš ï¸ No OpenAI API key configured")
                return None
            
            client = openai.OpenAI(api_key=api_key)
            
            prompt = f"""Eres un experto en extracciÃ³n de datos de bienes raÃ­ces de Costa Rica.

Analiza el siguiente texto extraÃ­do de una propiedad en Coldwell Banker Costa Rica y extrae toda la informaciÃ³n posible.

INSTRUCCIONES IMPORTANTES:

1. **Precio (price_usd)**: MUY IMPORTANTE - Busca el precio en la secciÃ³n "TÃTULO Y PRECIO"
   - El precio aparece en formato: $1,750,000 o $750,000
   - Extrae SOLO los nÃºmeros sin sÃ­mbolos ($), sin comas (,), sin puntos decimales
   - Ejemplo: si ves "$1,750,000" â†’ extrae "1750000"
   - Ejemplo: si ves "$750,000" â†’ extrae "750000"
   - Si NO encuentras precio, usa null

2. **TÃ­tulo profesional**: Genera un tÃ­tulo atractivo y profesional en ESPAÃ‘OL que resuma la propiedad. 
   - Para terrenos: Incluye el tamaÃ±o y ubicaciÃ³n (ej: "Terreno Comercial de 360 mÂ² en Curridabat")
   - Para casas/apartamentos: Incluye tipo, tamaÃ±o, y ubicaciÃ³n (ej: "Casa de Lujo de 250 mÂ² en EscazÃº")
   - NO uses el tÃ­tulo exacto del sitio web si es muy largo o poco claro

3. **DescripciÃ³n profesional**: Genera UNA descripciÃ³n profesional en ESPAÃ‘OL de 3-4 oraciones que sintetice toda la informaciÃ³n clave:
   - CaracterÃ­sticas principales (tamaÃ±o, ubicaciÃ³n, zonificaciÃ³n si es terreno)
   - CaracterÃ­sticas Ãºnicas o especiales (zonificaciÃ³n comercial, acceso a transporte pÃºblico, ubicaciÃ³n estratÃ©gica)
   - Potencial de desarrollo o uso
   - Condiciones especiales (muros perimetrales, edificaciones existentes, etc.)
   - NO copies y pegues toda la descripciÃ³n del sitio - sintetiza lo mÃ¡s importante

4. **TamaÃ±o del lote (lot_size_m2)**: MUY IMPORTANTE para terrenos
   - Busca tÃ©rminos: "superficie", "Ã¡rea del terreno", "lot size", "lote de", "terreno de"
   - Convierte unidades: 1 acre = 4046.86 mÂ², 1 sqft = 0.092903 mÂ², 1 hectÃ¡rea = 10000 mÂ²
   - Si encuentras el Ã¡rea de construcciÃ³n Y el Ã¡rea del lote, usa el Ã¡rea del lote para lot_size_m2
   - Para terrenos SIN construcciÃ³n, lot_size_m2 y area_m2 pueden ser el mismo valor

5. **Ãrea construida (area_m2)**: Ãrea de construcciÃ³n o edificaciÃ³n
   - Para terrenos SIN construcciÃ³n, puede ser null o igual a lot_size_m2 si no se especifica
   - Convierte sqft a mÂ² si es necesario

6. **Tipo de propiedad (property_type)**: "Terreno", "Casa", "Apartamento", "Condominio", "Lote", etc.

7. **Estado del listado (listing_type)**: Siempre "Venta" para Coldwell Banker (es un sitio de ventas)

8. **ZonificaciÃ³n**: Para terrenos, extrae informaciÃ³n de uso de suelo (Comercial, Residencial de Baja Densidad, etc.)

9. **Amenidades**: Lista TODO lo que encuentres en caracterÃ­sticas/amenidades

TEXTO A ANALIZAR:
{text_content}

Responde ÃšNICAMENTE con un objeto JSON vÃ¡lido (sin markdown, sin ```json):
{{
  "title": "TÃ­tulo profesional en espaÃ±ol",
  "price_usd": "solo el nÃºmero sin sÃ­mbolos ni comas",
  "property_type": "Terreno/Casa/Apartamento/etc",
  "listing_type": "Venta",
  "location": "ciudad, provincia",
  "city": "ciudad",
  "province": "provincia",
  "country": "Costa Rica",
  "bedrooms": nÃºmero o null,
  "bathrooms": nÃºmero decimal o null,
  "area_m2": nÃºmero decimal (Ã¡rea construida) o null,
  "lot_size_m2": nÃºmero decimal (Ã¡rea del lote/terreno) o null,
  "parking_spaces": "nÃºmero o null",
  "description": "descripciÃ³n profesional de 3-4 oraciones en espaÃ±ol",
  "amenities": ["lista", "de", "amenidades"],
  "zoning": "Residencial|Comercial|Mixto|etc (si se especifica)",
  "hoa_fee": "nÃºmero mensual en USD o null",
  "taxes": "nÃºmero anual en USD o null",
  "year_built": "nÃºmero (aÃ±o) o null",
  "video_url": "url de video o null",
  "brochure_url": "url del brochure/pdf o null"
}}"""
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Eres un experto en extracciÃ³n de datos de bienes raÃ­ces. Respondes ÃšNICAMENTE con JSON vÃ¡lido, sin markdown."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=1500
            )
            
            content = response.choices[0].message.content.strip()
            
            # Remove markdown code blocks if present
            if content.startswith('```'):
                content = content.split('```')[1]
                if content.startswith('json'):
                    content = content[4:]
                content = content.strip()
            
            data = json.loads(content)
            
            print(f"âœ… AI enhancement successful: {len(data)} campos extraÃ­dos")
            
            return data
            
        except json.JSONDecodeError as e:
            print(f"âŒ Error parsing AI response as JSON: {e}")
            print(f"Response content: {content[:500]}")
            return None
        except Exception as e:
            print(f"âŒ Error in AI enhancement: {e}")
            return None
    
    def extract_title(self, soup: BeautifulSoup) -> Optional[str]:
        """Extract property title."""
        # Try title-wrap section
        title_section = soup.find('div', class_='title-wrap')
        if title_section:
            title = title_section.find('h1')
            if title:
                return title.get_text(strip=True)
        
        return super().extract_title(soup)
    
    def extract_price(self, soup: BeautifulSoup) -> Optional[Decimal]:
        """Extract price from title-wrap section."""
        title_section = soup.find('div', class_='title-wrap')
        if title_section:
            price_text = title_section.get_text()
            match = re.search(r'\$\s*([\d,]+)', price_text)
            if match:
                price_str = match.group(1).replace(',', '')
                try:
                    return Decimal(price_str)
                except:
                    pass
        
        return super().extract_price(soup)
    
    def extract_bedrooms(self, soup: BeautifulSoup) -> Optional[int]:
        """Extract bedrooms from ul-specs."""
        specs = soup.find('ul', class_='ul-specs')
        if specs:
            text = specs.get_text()
            match = re.search(r'(\d+)\s*(bed|habitacion|dormitorio)', text, re.IGNORECASE)
            if match:
                return int(match.group(1))
        
        # Try more-details section
        more_details = soup.find('div', class_='more-details')
        if more_details:
            text = more_details.get_text()
            match = re.search(r'(\d+)\s*(bed|habitacion|dormitorio)', text, re.IGNORECASE)
            if match:
                return int(match.group(1))
        
        return super().extract_bedrooms(soup)
    
    def extract_bathrooms(self, soup: BeautifulSoup) -> Optional[Decimal]:
        """Extract bathrooms from ul-specs."""
        specs = soup.find('ul', class_='ul-specs')
        if specs:
            text = specs.get_text()
            match = re.search(r'(\d+\.?\d*)\s*(bath|baÃ±o)', text, re.IGNORECASE)
            if match:
                return Decimal(match.group(1))
        
        # Try more-details section
        more_details = soup.find('div', class_='more-details')
        if more_details:
            text = more_details.get_text()
            match = re.search(r'(\d+\.?\d*)\s*(bath|baÃ±o)', text, re.IGNORECASE)
            if match:
                return Decimal(match.group(1))
        
        return super().extract_bathrooms(soup)
    
    def extract_area(self, soup: BeautifulSoup) -> Optional[Decimal]:
        """Extract building area from specs."""
        specs = soup.find('ul', class_='ul-specs')
        if specs:
            text = specs.get_text()
            # Look for sq ft or m2
            match = re.search(r'([\d,]+\.?\d*)\s*(sq\s*ft|sqft|m[Â²2])', text, re.IGNORECASE)
            if match:
                value_str = match.group(1).replace(',', '')
                try:
                    value = Decimal(value_str)
                    # Convert sq ft to m2 if needed
                    if 'ft' in match.group(2).lower():
                        value = value * Decimal('0.092903')
                    return value
                except:
                    pass
        
        return super().extract_area(soup)
    
    def extract_description(self, soup: BeautifulSoup) -> Optional[str]:
        """Extract property description."""
        # Try desc-wrap section (main description container)
        desc_wrap = soup.find('div', class_='desc-wrap')
        if desc_wrap:
            # Try to get the complete description first
            desc_complete = desc_wrap.find('div', class_='desc-content-complete')
            if desc_complete:
                # Remove "Read More" / "Leer menos" links
                for link in desc_complete.find_all('a', class_='read-toggle'):
                    link.decompose()
                text = desc_complete.get_text(separator='\n', strip=True)
                if text:
                    return text
            
            # Fallback to partial description
            desc_partial = desc_wrap.find('div', class_='desc-content-partial')
            if desc_partial:
                for link in desc_partial.find_all('a', class_='read-toggle'):
                    link.decompose()
                text = desc_partial.get_text(separator='\n', strip=True)
                if text:
                    return text
            
            # Try general desc-content
            desc_content = desc_wrap.find('div', class_='desc-content')
            if desc_content:
                # Remove read-toggle links
                for link in desc_content.find_all('a', class_='read-toggle'):
                    link.decompose()
                text = desc_content.get_text(separator='\n', strip=True)
                if text:
                    return text
        
        # Try property-description as fallback
        desc = soup.find('div', class_='property-description')
        if desc:
            return desc.get_text(separator='\n', strip=True)
        
        # Try meta description as last resort
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        if meta_desc:
            content = meta_desc.get('content', '').strip()
            if content:
                return content
        
        return super().extract_description(soup)
    
    def extract_amenities(self, soup: BeautifulSoup) -> list:
        """Extract amenities from property-features."""
        amenities = []
        features_section = soup.find('div', class_='property-features')
        if features_section:
            # Find list items
            items = features_section.find_all('li')
            for item in items:
                amenity = item.get_text(strip=True)
                if amenity:
                    amenities.append(amenity)
        
        return amenities if amenities else super().extract_amenities(soup)
    
    def extract_latitude(self, soup: BeautifulSoup) -> Optional[Decimal]:
        """Extract latitude from map iframe."""
        # Look for Google Maps iframe
        iframe = soup.find('iframe', src=lambda x: x and 'google.com/maps' in x)
        if iframe:
            src = iframe.get('src', '')
            # Extract coordinates from iframe src
            # Format: https://maps.google.com/maps?q=LAT,LNG&...
            match = re.search(r'[?&]q=([-\d.]+),([-\d.]+)', src)
            if match:
                try:
                    return Decimal(match.group(1))
                except:
                    pass
        
        # Try map-container data attributes
        map_container = soup.find('div', class_='map-container')
        if map_container:
            lat = map_container.get('data-lat') or map_container.get('data-latitude')
            if lat:
                try:
                    return Decimal(lat)
                except:
                    pass
        
        return super().extract_latitude(soup)
    
    def extract_longitude(self, soup: BeautifulSoup) -> Optional[Decimal]:
        """Extract longitude from map iframe."""
        # Look for Google Maps iframe
        iframe = soup.find('iframe', src=lambda x: x and 'google.com/maps' in x)
        if iframe:
            src = iframe.get('src', '')
            match = re.search(r'[?&]q=([-\d.]+),([-\d.]+)', src)
            if match:
                try:
                    return Decimal(match.group(2))
                except:
                    pass
        
        # Try map-container data attributes
        map_container = soup.find('div', class_='map-container')
        if map_container:
            lng = map_container.get('data-lng') or map_container.get('data-longitude')
            if lng:
                try:
                    return Decimal(lng)
                except:
                    pass
        
        return super().extract_longitude(soup)
    
    def extract_location(self, soup: BeautifulSoup) -> Optional[str]:
        """Extract full location string."""
        # Try to find h3 with location info in main content sections
        sections = soup.find_all('section')
        for section in sections:
            h3_tags = section.find_all('h3')
            for h3 in h3_tags:
                text = h3.get_text(strip=True)
                # Check if it contains location keywords
                if 'ubicaciÃ³n:' in text.lower() or 'location:' in text.lower():
                    # Split and get the part after the colon
                    parts = text.split(':', 1)
                    if len(parts) > 1:
                        location = parts[1].strip()
                        if location:
                            return location
        
        # Try location-wrap section
        location_section = soup.find('div', class_='location-wrap')
        if location_section:
            # Try to find address in the section
            addr = location_section.find('address')
            if addr:
                return addr.get_text(strip=True)
            
            # Or try paragraphs
            paragraphs = location_section.find_all('p')
            if paragraphs:
                return paragraphs[0].get_text(strip=True)
        
        # Fallback: Use OpenAI to extract location from description
        description = self.extract_description(soup)
        if description and len(description) > 50:
            try:
                location = self._extract_location_with_ai(description)
                if location:
                    return location
            except Exception as e:
                print(f"Error extracting location with AI: {e}")
        
        return super().extract_location(soup)
    
    def extract_address(self, soup: BeautifulSoup) -> Optional[str]:
        """Extract address from location-wrap or any h3 with location info."""
        # Try to find h3 with location info in main content sections
        sections = soup.find_all('section')
        for section in sections:
            h3_tags = section.find_all('h3')
            for h3 in h3_tags:
                text = h3.get_text(strip=True)
                # Check if it contains location keywords
                if 'ubicaciÃ³n:' in text.lower() or 'location:' in text.lower():
                    # Split and get the part after the colon
                    parts = text.split(':', 1)
                    if len(parts) > 1:
                        location = parts[1].strip()
                        if location:
                            return location
        
        # Try location-wrap section
        location_section = soup.find('div', class_='location-wrap')
        if location_section:
            # Try to find address in the section
            addr = location_section.find('address')
            if addr:
                return addr.get_text(strip=True)
            
            # Or try paragraphs
            paragraphs = location_section.find_all('p')
            if paragraphs:
                return paragraphs[0].get_text(strip=True)
        
        # Fallback: Use OpenAI to extract location from description
        description = self.extract_description(soup)
        if description and len(description) > 50:
            try:
                location = self._extract_location_with_ai(description)
                if location:
                    return location
            except Exception as e:
                print(f"Error extracting location with AI: {e}")
        
        return super().extract_address(soup)
    
    def _extract_location_with_ai(self, description: str) -> Optional[str]:
        """Use OpenAI to extract location from description."""
        try:
            api_key = settings.OPENAI_API_KEY
            if not api_key:
                return None
            
            client = openai.OpenAI(api_key=api_key)
            
            instruction = "Extract the location (city, region, country) from this property description. Return ONLY the location in format: 'City, Region' or 'City, Region, Country'. If no clear location is found, return 'Unknown'."
            prompt = f"{instruction}\n\nDescription:\n{description[:1000]}\n\nLocation:"
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a real estate data extraction assistant. Extract location information accurately and concisely."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=100
            )
            
            location = response.choices[0].message.content.strip()
            
            # Validate the response
            if location and location.lower() not in ['unknown', 'n/a', 'none', '']:
                return location
            
            return None
            
        except Exception as e:
            print(f"OpenAI extraction error: {e}")
            return None
