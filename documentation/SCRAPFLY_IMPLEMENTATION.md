# ğŸš€ GuÃ­a de ImplementaciÃ³n Scrapfly

## âœ… Cambios Implementados

### 1. **Dependencias** (`requirements.txt`)
```bash
scrapfly-sdk==1.1.1
```

### 2. **ConfiguraciÃ³n** (`config/settings/base.py`)
```python
# Scrapfly API for advanced anti-bot bypass
SCRAPFLY_API_KEY = env('SCRAPFLY_API_KEY', default=None)
SCRAPFLY_ENABLED = env.bool('SCRAPFLY_ENABLED', default=True)
```

### 3. **Scraper Inteligente** (`core/scraping/scraper.py`)

Ahora el scraper elige automÃ¡ticamente el mejor mÃ©todo:

1. **Scrapfly** â†’ Sitios con Cloudflare (encuentra24.com)
2. **Playwright** â†’ Sitios JS-heavy sin Cloudflare
3. **httpx** â†’ Sitios HTML estÃ¡ticos

---

## ğŸ“¦ InstalaciÃ³n

### Paso 1: Instalar dependencias

```bash
cd backend
pip install scrapfly-sdk==1.1.1
```

O instala todas las dependencias:

```bash
pip install -r requirements.txt
```

### Paso 2: Configurar API Key

1. RegÃ­strate en Scrapfly: https://scrapfly.io/register
2. ObtÃ©n tu API key del dashboard: https://scrapfly.io/dashboard
3. Agrega a tu archivo `.env`:

```bash
# Scrapfly API
SCRAPFLY_API_KEY=scp-live-YOUR_KEY_HERE
SCRAPFLY_ENABLED=True
```

---

## ğŸ¯ Uso

El scraper funciona igual que antes, pero ahora usa Scrapfly automÃ¡ticamente para sitios protegidos:

```python
from core.scraping.scraper import WebScraper

scraper = WebScraper()

# Scrapea encuentra24 (usarÃ¡ Scrapfly automÃ¡ticamente)
result = await scraper.scrape('https://encuentra24.com/...')

# Scrapea Coldwell Banker (usarÃ¡ Playwright o httpx)
result = await scraper.scrape('https://coldwellbanker.cr/...')

print(result['html'])
print(result['method'])  # 'scrapfly', 'playwright', o 'httpx'
print(result.get('api_cost'))  # Costo en credits de Scrapfly
```

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ URL Request                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WebScraper._should_use_scrapfly(url)                â”‚
â”‚ Â¿Es encuentra24.com u otro con Cloudflare?          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        âœ… YES              â”‚              âŒ NO
         â†“                  â”‚                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scrapfly API     â”‚        â”‚    â”‚ Â¿JS-heavy site?    â”‚
â”‚ - Cloudflareâœ…   â”‚        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ - Residential    â”‚        â”‚       YES â”‚      NO
â”‚ - JS rendering   â”‚        â”‚           â†“      â†“
â”‚ $30/mes          â”‚        â”‚    Playwright  httpx
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚    (free)      (free)
         â†“                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scraped HTML â†’ BeautifulSoup â†’ OpenAI â†’ Property    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ’° Costos

**Plan Discovery: $30/mes**

- 200,000 API credits
- Para Cloudflare bypass: 31 credits/pÃ¡gina
- **Capacidad:** 6,451 pÃ¡ginas/mes
- **Tu uso:** ~1,000 pÃ¡ginas/mes = **$30/mes**

---

## ğŸ§ª Testing

### Test 1: Verificar instalaciÃ³n

```bash
python manage.py shell
```

```python
from core.scraping.scraper import WebScraper

scraper = WebScraper()
# Debe mostrar: "ğŸš€ Scrapfly enabled - Anti-bot bypass ready"
```

### Test 2: Scrapear encuentra24

```python
import asyncio
from core.scraping.scraper import WebScraper

async def test():
    scraper = WebScraper()
    result = await scraper.scrape('https://encuentra24.com/costa-rica-es/bienes-raices-venta-casas')
    print(f"Method: {result['method']}")  # Should be 'scrapfly'
    print(f"Cost: {result.get('api_cost')} credits")
    print(f"HTML length: {len(result['html'])} chars")
    return result

result = asyncio.run(test())
```

### Test 3: Verificar que sitios simples no usan Scrapfly

```python
async def test_simple_site():
    scraper = WebScraper()
    result = await scraper.scrape('https://httpbin.org/html')
    print(f"Method: {result['method']}")  # Should be 'httpx' or 'playwright'
    # No debe usar Scrapfly (no gastar credits)
    
asyncio.run(test_simple_site())
```

---

## ğŸ” Logs

El scraper loggearÃ¡ automÃ¡ticamente quÃ© mÃ©todo usa:

```
ğŸš€ Scrapfly enabled - Anti-bot bypass ready
ğŸ›¡ï¸ Cloudflare-protected site detected: encuentra24.com
ğŸš€ Using Scrapfly for Cloudflare bypass: https://encuentra24.com/...
âœ… Scrapfly success - API cost: 31 credits
```

---

## ğŸ› ï¸ Troubleshooting

### Error: "Scrapfly SDK not installed"

```bash
pip install scrapfly-sdk
```

### Error: "Invalid API key"

Verifica tu `.env`:
```bash
SCRAPFLY_API_KEY=scp-live-YOUR_ACTUAL_KEY
```

### Error: "Quota limit reached"

Has consumido los 200k credits del mes. Opciones:
1. Espera al prÃ³ximo ciclo de facturaciÃ³n
2. Upgrade a plan Professional ($75/mes)
3. Desactiva Scrapfly temporalmente:
   ```bash
   SCRAPFLY_ENABLED=False
   ```

### Scrapfly no se usa para encuentra24

Verifica que el dominio estÃ© en la lista:
```python
# core/scraping/scraper.py
CLOUDFLARE_PROTECTED_DOMAINS = [
    'encuentra24.com',  # âœ… Debe estar aquÃ­
]
```

---

## ğŸ“Š Monitoreo

### Ver uso actual

Dashboard de Scrapfly: https://scrapfly.io/dashboard/monitoring

### Ver credits restantes

```python
from scrapfly import ScrapflyClient

client = ScrapflyClient(key='YOUR_KEY')
account = client.account()
print(account)
```

---

## ğŸ” Seguridad

**Importante:** No commitees tu API key al repositorio.

Verifica que `.env` estÃ© en `.gitignore`:

```bash
# .gitignore
.env
.env.local
*.env
```

---

## ğŸš€ Deployment

### DigitalOcean App Platform

Agrega la variable de entorno en el dashboard:

1. Ve a Settings â†’ Environment Variables
2. Agrega:
   ```
   SCRAPFLY_API_KEY = scp-live-YOUR_KEY
   SCRAPFLY_ENABLED = true
   ```

3. Redeploy la app

### Docker

En tu `docker-compose.yml`:

```yaml
services:
  backend:
    environment:
      - SCRAPFLY_API_KEY=${SCRAPFLY_API_KEY}
      - SCRAPFLY_ENABLED=true
```

---

## âœ¨ Features Adicionales

### Screenshot de pÃ¡ginas (gratis con el plan)

```python
scrape_config = ScrapeConfig(
    url=url,
    asp=True,
    render_js=True,
    screenshots={
        'main': 'fullpage'  # Screenshot de pÃ¡gina completa
    }
)
```

### Extraer datos con LLM integrado

```python
scrape_config = ScrapeConfig(
    url=url,
    asp=True,
    extraction_prompt="Extract property price, bedrooms, and location"
)
# Scrapfly usarÃ¡ su propio LLM para extraer datos
```

---

## ğŸ“š DocumentaciÃ³n Oficial

- Scrapfly Docs: https://scrapfly.io/docs
- Python SDK: https://scrapfly.io/docs/sdk/python
- Pricing: https://scrapfly.io/pricing
- Dashboard: https://scrapfly.io/dashboard

---

## âœ… Checklist de ImplementaciÃ³n

- [x] Instalar `scrapfly-sdk` en requirements.txt
- [x] Agregar `SCRAPFLY_API_KEY` a settings
- [x] Implementar `_scrape_with_scrapfly()` mÃ©todo
- [x] Modificar lÃ³gica de decisiÃ³n en `scrape()`
- [ ] **Configurar API key en `.env`**
- [ ] **Instalar dependencias** (`pip install -r requirements.txt`)
- [ ] **Test scraping de encuentra24**
- [ ] **Verificar logs de Scrapfly**
- [ ] **Monitorear uso de credits**
- [ ] **Deploy con variables de entorno**

---

## ğŸ‰ Â¡Listo!

Tu scraper ahora usa Scrapfly automÃ¡ticamente para bypass de Cloudflare.

**Siguiente paso:** Configura tu API key y prueba scrapear encuentra24.com
